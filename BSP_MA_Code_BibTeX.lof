\babel@toc {english}{}
\babel@toc {english}{}
\contentsline {figure}{\numberline {\small 1\normalsize }{\ignorespaces Most popular programming languages throughout the years (Source: \cite {lang_ratings}).\relax }}{2}{figure.caption.6}% 
\contentsline {figure}{\numberline {\small 2\normalsize }{\ignorespaces Visualization of how \textit {npc\_arr} will exist in memory\relax }}{3}{figure.caption.7}% 
\contentsline {figure}{\numberline {\small 3\normalsize }{\ignorespaces "\textit {\textbf {Starting with 1980 performance as a baseline, the gap in performance between memory and processors is plotted over time}. Note that the vertical axis must be on a logarithmic scale to record the size of the processor-DRAM performance gap. The memory baseline is 64 KB DRAM in 1980, with a 1.07 per year performance improvement in latency (see Figure 5.13 on page 313). The processor line assumes a 1.25 improvement per year until 1986, and a 1.52 improvement until 2004, and a 1.20 improvement thereafter}" (Source: \cite [p. 289]{hennessy})\relax }}{5}{figure.caption.8}% 
\contentsline {figure}{\numberline {\small 4\normalsize }{\ignorespaces Exemplary, simplified model of a CPU core and its several cache modules (Source: \cite [p. 15]{Drepper})\relax }}{6}{figure.caption.9}% 
\contentsline {figure}{\numberline {\small 5\normalsize }{\ignorespaces NPCs inside cache-lines, where blue is relevant data and red blocks represent unused data\relax }}{14}{figure.caption.12}% 
\contentsline {figure}{\numberline {\small 6\normalsize }{\ignorespaces Cache-line efficiency comparing NPCs represented as SOA and AOS.\relax }}{15}{figure.caption.16}% 
\contentsline {figure}{\numberline {\small 7\normalsize }{\ignorespaces xyz and vel blocks inside cache-lines, where blue represents joint float[3] blocks of xyz data, green joint blocks of float[3] vel data and red is unused but intentional padding.\relax }}{16}{figure.caption.17}% 
\contentsline {figure}{\numberline {\small 8\normalsize }{\ignorespaces Unified/Grouped relevant data in a cache-line.\relax }}{17}{figure.caption.20}% 
\contentsline {figure}{\numberline {\small 9\normalsize }{\ignorespaces Relation of a record's stride and size to the read throughput, characterized as the memory mountain. (Source: \cite [p. 623]{bryant})\relax }}{18}{figure.caption.23}% 
\contentsline {figure}{\numberline {\small 10\normalsize }{\ignorespaces Parse tree for the if-stmt node.\relax }}{25}{figure.caption.34}% 
\contentsline {figure}{\numberline {\small 11\normalsize }{\ignorespaces Phases of a compiler (Source: \cite [p. 5]{aho}).\relax }}{26}{figure.caption.36}% 
\contentsline {figure}{\numberline {\small 12\normalsize }{\ignorespaces AST dump of Code \ref {foo_code} generated with \textit {clang -Xclang -ast-dump Foo.cpp}.\relax }}{27}{figure.caption.41}% 
\contentsline {figure}{\numberline {\small 13\normalsize }{\ignorespaces AST dump of Code \ref {foo_code} generated with some simple AST matchers in the easy to use \textit {clang-query} environment.\relax }}{28}{figure.caption.43}% 
\contentsline {figure}{\numberline {\small 14\normalsize }{\ignorespaces Excerpt of coops output on exemplary NPC and some arbitrary functions/loops\relax }}{34}{figure.caption.45}% 
\contentsline {figure}{\numberline {\small 15\normalsize }{\ignorespaces Relations depicted in function/member matrices\relax }}{40}{figure.caption.50}% 
\contentsline {figure}{\numberline {\small 16\normalsize }{\ignorespaces Good avg scaling.\relax }}{41}{figure.caption.52}% 
\contentsline {figure}{\numberline {\small 17\normalsize }{\ignorespaces Difficult evaluation for avg scaling.\relax }}{41}{figure.caption.52}% 
\contentsline {figure}{\numberline {\small 18\normalsize }{\ignorespaces Bad avg scaling with more fields.\relax }}{41}{figure.caption.52}% 
\contentsline {figure}{\numberline {\small 19\normalsize }{\ignorespaces Problem of even distribution.\relax }}{41}{figure.caption.52}% 
\contentsline {figure}{\numberline {\small 20\normalsize }{\ignorespaces Bad avg homogeneous field weights.\relax }}{42}{figure.caption.53}% 
\contentsline {figure}{\numberline {\small 21\normalsize }{\ignorespaces \textit {1-avg} prone to false positives as well.\relax }}{42}{figure.caption.53}% 
\contentsline {figure}{\numberline {\small 22\normalsize }{\ignorespaces Improved \textit {top/2} heuristic as it is able to rule out \textit {1-avg} errors but still not well.\relax }}{43}{figure.caption.55}% 
\contentsline {figure}{\numberline {\small 23\normalsize }{\ignorespaces Field weight categorization by combined scaling delimiters. Top hatched space is of high significance.\relax }}{44}{figure.caption.56}% 
\contentsline {figure}{\numberline {\small 24\normalsize }{\ignorespaces Scaling delimiters' errors can hardly be reasoned about and provide equally much punishment as benefit depending on the distribution.\relax }}{45}{figure.caption.58}% 
\contentsline {figure}{\numberline {\small 25\normalsize }{\ignorespaces Determination of significance groups with field weight deltas. Normalized differences are projected on the field weights' scale for visualization.\relax }}{45}{figure.caption.58}% 
\contentsline {figure}{\numberline {\small 26\normalsize }{\ignorespaces Aligned entities will be packed inside cache-lines. Reduced stride will be effective, as soon as it increases the amount of entities inside a cache-line.\relax }}{47}{figure.caption.59}% 
\contentsline {figure}{\numberline {\small 27\normalsize }{\ignorespaces Reduced stride will be effective as soon as it reduces the number of cache-lines needed to encompass an entity. Entities are split upon minimum amount of lines.\relax }}{47}{figure.caption.59}% 
\contentsline {figure}{\numberline {\small 28\normalsize }{\ignorespaces Exemplary field weights evaluated by our heuristic with the result, that its worth to make the split hot:[\textit {field\_a}, ...\textit {field\_e}], cold:[\textit {field\_d}, ...\textit {field\_h}].\relax }}{48}{figure.caption.60}% 
\contentsline {figure}{\numberline {\small 29\normalsize }{\ignorespaces Comparison of .bss and .data sizes for different initializations.\relax }}{54}{figure.caption.62}% 
\contentsline {figure}{\numberline {\small 30\normalsize }{\ignorespaces The free list's layout in memory. Starting with a (possible) initial padding, the instances here represented by nodes will be grouped in a way, that a maximum amount of nodes fits a cache-line. Each group is again aligned to the cache-lines (here 64 Byte) to guarantee minimal loads.\relax }}{58}{figure.caption.63}% 
\contentsline {figure}{\numberline {\small 31\normalsize }{\ignorespaces Screenshots of simple particle application. Left - original. Right - wrong shader on the fire because of semantic corruption. Deep copies of splitted instances no longer copy cold fields, but the pointer to the cold struct instance.\relax }}{67}{figure.caption.66}% 
\contentsline {figure}{\numberline {\small 32\normalsize }{\ignorespaces Visualization of how different AST contexts might include identical/redundant information when regarded in an abstract project scope.\relax }}{74}{figure.caption.67}% 
\contentsline {figure}{\numberline {\small 33\normalsize }{\ignorespaces Function calls and loops can interact in all sorts of forms in a program and recursion must be considered as it implicates similar behavior on access patterns as loops do.\relax }}{76}{figure.caption.68}% 
\contentsline {figure}{\numberline {\small 34\normalsize }{\ignorespaces Measurements for \textit {N} data entities and the resulting cache utilizations. The red line marks the 'post-optimization' values. Note that the \textit {D refs} graph uses a logarithmic scale so the increase in D refs as N grows actually becomes very large!\relax }}{79}{figure.caption.69}% 
\contentsline {figure}{\numberline {\small 35\normalsize }{\ignorespaces Measured runtimes for un-/optimized versions of our simple test code with rising N. These measurements have been made by using the Unix command \textit {time}.\relax }}{80}{figure.caption.70}% 
\contentsline {figure}{\numberline {\small 36\normalsize }{\ignorespaces The small test programs miss rates show improvement, as the cold data no longer resides unused in our cache. Note how the last level cache miss rates rise between 10,000 and 100,000 entities due to the total amount of our data exceeding the cache size.\relax }}{81}{figure.caption.71}% 
\contentsline {figure}{\numberline {\small 37\normalsize }{\ignorespaces The particle's field weighst according to COOP. The q1/2 are the quartiles, that together with the interquartile range define our spike points. Inside the mid fragment we will induce further significance grouping as discussed in section \ref {sig_groups}.\relax }}{82}{figure.caption.72}% 
\contentsline {figure}{\numberline {\small 38\normalsize }{\ignorespaces Observed delta times for both the optimized and unoptimized versions of our particle demo. The red line marks the delta times after the optimization was applied and shows that with our less frequently used fields externalized we can accomplish improvement. These measurements were made with approximately 96,000 particles.\relax }}{83}{figure.caption.73}% 
\contentsline {figure}{\numberline {\small 39\normalsize }{\ignorespaces Compared delta times of an optimized and an unoptimized build showing that COOP's metrics have major issues with variant behavior of splitted instances.\relax }}{84}{figure.caption.74}% 
\contentsline {figure}{\numberline {\small 40\normalsize }{\ignorespaces Example of how a Base class and a Sub class could exist in the cache. In this case externalizing the Base's fields will effectively not reduce the Sub class' size enough to reduce the necessary amount of cache-lines to encompass it.\relax }}{88}{figure.caption.76}% 
\contentsline {figure}{\numberline {\small 41\normalsize }{\ignorespaces Example of how a split in a sub class might be ineffective as soon, as its base's fields are brought into the picture.\relax }}{89}{figure.caption.77}% 
